#!/usr/bin/env Rscript

###
### QC Summary Script
###

### Aggregate all of the QC functionality into one script.
  ### PEAR
  ### Count Spikes - 25-bp
  ### Spike Removal
  ### MiXCR
  ### Decontamination
  ### Normalization

### disable scientific notation
options(scipen=999);
suppressWarnings(suppressMessages(library(ShortRead)))
suppressWarnings(suppressMessages(library(optparse)))

####################
### COMMAND LINE ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
####################

optlist <- list(
  make_option(
    c("-1", "--fastqFiles"),
    type = "character",
    help = "PEARed fastq files - for count spikes QC"
  ),
  make_option(
    c("-2", "--fastqNames"),
    type = "character",
    help = "Actual names of fastq files"
  ),
  make_option(
    c("-3", "--spikeCountFiles"),
    type = "character",
    help = "25-bp spike count files - for count spikes QC"
  ),
  make_option(
    c("-4", "--spikeCountNames"),
    type = "character",
    help = "Actual names of spike count files"
  ),
  make_option(
    c("-5", "--despikedFiles"),
    type = "character",
    help = "PEARed fastq file with spikes removed - for count spikes QC"
  ),
  make_option(
    c("-6", "--despikedNames"),
    type = "character",
    help = "Actual names of despiked files"
  ),
  make_option(
    c("-7", "--spikeCountOutput"),
    type = "character",
    help = "Output for aggregated count spikes QC."
  ),
  make_option(
    c("-8", "--mixcrReports"),
    type = "character",
    help = "Report files generated by MiXCR Align."
  ),
  make_option(
    c("-9", "--mixcrNames"),
    type = "character",
    help = "Actual names of report files"
  ),
  make_option(
    c("-a", "--alignOutput"),
    type = "character",
    help = "Output for MiXCR alignment QC."
  ),
  make_option(
    c("-k", "--assembleOutput"),
    type = "character",
    help = "Output for MiXCR assemble QC."
  ),
  make_option(
    c("-b", "--decontamQCFiles"),
    type = "character",
    help = "Individual QC files generated during decontamination"
  ),
  make_option(
    c("-c", "--decontamQCNames"),
    type = "character",
    help = "Actual names of decontamination QC files"
  ),
  make_option(
    c("-d", "--decontamOutput"),
    type = "character",
    help = "Output for decontamination QC."
  ),
  make_option(
    c("-e", "--decontamCloneFiles"),
    type = "character",
    help = "Raw, decontaminated clone files generated by exportClones and then decontaminated."
  ),
  make_option(
    c("-f", "--decontamCloneNames"),
    type = "character",
    help = "Actual names of decontaminated clone files."
  ),
  make_option(
    c("-g", "--normCloneFiles"),
    type = "character",
    help = "Normalized clonotype count files. Generated by exportClones, then decontaminated, then normalized."
  ),
  make_option(
    c("-h", "--normCloneNames"),
    type = "character",
    help = "Actual names of normalized clone files"
  ),
  make_option(
    c("-i", "--normOutput"),
    type = "character",
    help = "Output for normalization QC."
  ),
  make_option(
    c("-j", "--debug"),
    type = "logical",
    help = "TRUE - run debug; FALSE - do not run debug."
  )
)

### Parse Command Line
p <- OptionParser(usage = "%prog -1 fastqFiles -2 fastqNames -3 spikeCountFiles -4 spikeCountNames -5 despikedFiles -6 despikedNames -7 spikeCountOutput
                  -8 mixcrReports -9 mixcrNames -a alignOutput -k assembleOutput -b decontamQCFiles -c decontamQCNames -d decontamOutput -e decontamCloneFiles
                  -f decontamCloneNames -g normCloneFiles -h normCloneNames -i normOutput -j debug",
                  option_list = optlist)
args <- parse_args(p)
opt <- args$options
arguments <- commandArgs(trailingOnly=TRUE)

### Count Spikes and Remove Spikes
fastqFiles_v <- args$fastqFiles
fastqNames_v <- args$fastqNames

spikeCountFiles_v <- args$spikeCountFiles
spikeCountNames_v <- args$spikeCountNames

despikedFiles_v <- args$despikedFiles
despikedNames_v <- args$despikedNames

spikeCountOut_v <- args$spikeCountOutput

### MiXCR Align and Assemble
mixcrReports_v <- args$mixcrReports
mixcrNames_v <- args$mixcrNames
alignOut_v <- args$alignrOutput
assembleOut_v <- args$assembleOutput

### Decontamination
decontamQCFiles_v <- args$decontamQCFiles
decontamQCNames_v <- args$decontamQCNames
decontamOut_v <- args$decontamOutput

### Normalization
decontamCloneFiles_v <- args$decontamCloneFiles
decontamCloneNames_v <- args$decontamCloneNames

normCountFiles_v <- args$normCloneFiles
normCountNames_v <- args$normCloneNames

normOut_v <- args$normOutput

debug_v <- args$debug

###################
### For Testing ###
###################

# fastqFiles_v <- "~/galaxy/test-data/count.spikes/pear_S10_data.fastq"
# fastqNames_v <- "~/galaxy/test-data/qc/temp/fastqNames.txt"
# 
# spikeCountFiles_v <- "~/galaxy/test-data/count.spikes/25bp_S10_counts.txt"
# spikeCountNames_v <- "~/galaxy/test-data/qc/temp/spikeCountNames.txt"
# 
# despikedFiles_v <- "~/galaxy/test-data/remove.spikes/reads_S10_data.fastq"
# despikedNames_v <- "~/galaxy/test-data/qc/temp/despikedNames.txt"
# 
# spikeCountOut_v <- "testSpikeCountOut.txt"
# 
# alignReports_v <- "~/galaxy/test-data/mixcr/mixcr_S10_alignReport.txt"
# alignNames_v <- "~/galaxy/test-data/qc/temp/alignNames.txt"
# alignOut_v <- "testAlignOut.txt"
# 
# assembleReports_v <- "~/galaxy/test-data/mixcr/mixcr_S10_assembleReport.txt"
# assembleNames_v <- "~/galaxy/test-data/qc/temp/assembleNames.txt"
# assembleOut_v <- "testAssembleOut.txt"
# 
# decontamQCFiles_v <- "~/galaxy/test-data/decontam/decontam_S10_qc.txt"
# decontamQCNames_v <- "~/galaxy/test-data/qc/temp/decontamQCNames.txt"
# decontamOut_v <- "testDecontamOut.txt"
# 
# decontamCloneFiles_v <- "~/galaxy/test-data/decontam/decontam_S10_clones.txt"
# decontamCloneNames_v <- "~/galaxy/test-data/qc/temp/decontamCloneNames.txt"
# 
# normCountFiles_v <- "~/galaxy/test-data/normalization/normalize_S10_clones.txt"
# normCountNames_v <- "~/galaxy/test-data/qc/temp/normNames.txt"
# 
# normOut_v <- "testNormOut.txt"
# debug_v <- T

#################
### Functions ###
#################
dsName <- function(dataSetName_v){
  # Return last directory from file path and file name of galaxy dataset.dat path
  # dataSetName_v - single element of a galaxy dataset path (e.g. /database/files/000/dataset123.dat)
  splitName_v <- strsplit(dataSetName_v, split = "/")[[1]]
  x_v <- length(splitName_v)
  newName_v <- paste(splitName_v[c((x_v-1),x_v)], collapse = "/")
  return(newName_v)
}

extractRecord <- function(string_v, record_v, names_v){
  # Extract the number and percent values from mixcr records
  # string_v - character vector to distinguish which element of record to look at
  # record_v - assemblage of character records read in from mixcr record
  # names_v - character vectors to use as column names
  grep_v <- grep(string_v, record_v, value = T)
  if (length(grep_v) == 0){
    final_v <- c(NA, NA)
    names(final_v) <- names_v
  } else {
    partial_v <- unlist(strsplit(trimws(strsplit(grep_v, ":")[[1]][2]), " "))
    final_v <- as.numeric(gsub("\\(|%|\\)", "", partial_v))
    names(final_v) <- names_v
  }
  return(final_v)
}

######################################
### Count Spikes and Remove Spikes ###
######################################

### Creates QC report that was previously housed in the count.spikes script, and also creates
### the aggregate summary that was previously hosued in the count.spikes.QC script

### Separate input files
fastqFiles_v <- unlist(strsplit(fastqFiles_v, ','))
despikedFiles_v <- unlist(strsplit(despikedFiles_v, ','))
spikeCountFiles_v <- unlist(strsplit(spikeCountFiles_v, ','))

### Read in names
fastqNames_df <- read.table(fastqNames_v, header = F, sep = '\t', stringsAsFactors = F)
spikeCountNames_df <- read.table(spikeCountNames_v, header = F, sep = '\t', stringsAsFactors = F)
despikedNames_df <- read.table(despikedNames_v, header = F, sep = '\t', stringsAsFactors = F)

### Check Names
if (debug_v){
  print("Fastq Names: ")
  print(fastqNames_df)
  print("Spike Count Names: ")
  print(spikeCountNames_df)
  print("Despiked Fastq Names: ")
  print(despikedNames_df)
}

### Compare
fastqToSpikeCompare_v <- which(fastqNames_df$V1 != spikeCountNames_df$V1)
spikeToDespikeCompare_v <- which(spikeCountNames_df$V1 != despikedNames_df$V1)

if (length(fastqToSpikeCompare_v) > 0 | length(spikeToDespikeCompare_v) > 0){
  stop("PEAR fastq, spike count, and despiked fastq files do not match")
}

### Perform QC operations on each file
if (debug_v) print("Begin Spike Count/Remove")

for (i in 1:length(fastqFiles_v)){
  if (debug_v) {print("Currently on: "); print(i)}

    ## Read in data
    fastqReads_srq <- readFastq(fastqFiles_v[i])
    despikedReads_srq <- readFastq(despikedFiles_v[i])
    spikeTable_df <- read.table(spikeCountFiles_v[i], sep = '\t', stringsAsFactors = F, header = T)
    if (debug_v) {print("Spike Table: "); print(head(spikeTable_df))}

    ## Get File information
    currFastqDatasetName_v <- dsName(fastqFiles_v[i])
    currDespikedDatasetName_v <- dsName(despikedFiles_v[i])
    currSpikeCountDatasetName_v <- dsName(spikeCountFiles_v[i])
    
    ## Get sample names
    currFastqSampleName_v <- fastqNames_df$V1[i]
        
    ## Calculate number of reads of each type
    numFastqs_v <- length(fastqReads_srq)
    numDespiked_v <- length(despikedReads_srq)
    spikedReads_v <- sum(spikeTable_df$spike.count)

    ##
    ## Calculate various QC statistics
    ##

    ## Total reads removed
    numRemoved_v <- numFastqs_v - numDespiked_v

    ## Percent reads retained
    pctReadsKept_v <- round((numDespiked_v / numFastqs_v * 100), digits = 1)

    ## Percent spiked reads
    pctSpiked_v <- (spikedReads_v / numFastqs_v) * 100
    
    if (debug_v){
      cat("num.fastq\n", numFastqs_v, '\n')
      cat("num.despiked\n", numDespiked_v, '\n')
      cat("spiked.reads\n", spikedReads_v, "\n")
      cat("reads.removed", numRemoved_v, '\n')
      cat("pct.reads.retained", pctReadsKept_v, '\n')
      cat("spike.percent", pctSpiked_v, '\n')
      
      print("Begin df")
    }
    ## Aggregate into a single row data frame
    summaryData_df <- data.frame("Sample" = currFastqSampleName_v, "Total_Reads" = numFastqs_v,
                                 "Despiked_Reads" = numDespiked_v, "Reads_Removed" = numRemoved_v,
                                 "Pct_Kept" = pctReadsKept_v, "Spiked_Reads" = spikedReads_v,
                                 "Pct_Spike" = pctSpiked_v, "Galaxy_Fastq_Name" = currFastqDatasetName_v,
                                 "Galaxy_Despiked_Name" = currDespikedDatasetName_v, 
                                 "Galaxy_SpikeCountName_v" = currSpikeCountDatasetName_v)
    if (debug_v) print("end summary df")
    
    ## Extract spike counts and turn into single row data frame
    spikeOut_df <- as.data.frame(spikeTable_df$spike.count)
    rownames(spikeOut_df) <- spikeTable_df$SPIKE_ID
    spikeOut_df <- t(spikeOut_df)
    
    ## Combine into one data frame
    newRow_df <- cbind(summaryData_df, spikeOut_df)
    if ( i == 1){
      if (debug_v) print("i == 1")
        summaryOut_df <- newRow_df
        if (debug_v) {print(summaryOut_df); print("Done i == 1")}
    } else {
      if (debug_v) print("i != 1")
        summaryOut_df <- rbind(summaryOut_df, newRow_df)
        if (debug_v) print("Done i != 1")
    }   #   else
    
}   #   for

###################
### MiXCR Align ###
###################

if (debug_v) print("Begin MiXCR")

### Separate input files
mixcrReports_v <- unlist(strsplit(mixcrReports_v, ','))

### Create empty data frame
align_df <- assemble_df <- data.frame()

### Summarize info from each report file
for (i in 1:length(mixcrReports_v)){

    ## Get Record
    curr.record <- readLines(mixcrReports_v[i])

## Date
    curr.date <- grep("Analysis date", curr.record, value = T)[1]
    curr.date <- trimws(gsub("[A-z ]+:|[0-9]+:.*PDT ", "", curr.date))
    names(curr.date) <- "analysis.date"

    ## I/0
    curr.input <- basename(trimws(strsplit(grep("Input file", curr.record, value = T)[1], ':')[[1]][2]))
    curr.output <- basename(trimws(strsplit(grep("Output file", curr.record, value = T)[1], ':')[[1]][2]))
    curr.output2 <- basename(trimws(strsplit(grep("Output file", curr.record, value = T)[2], ':')[[1]][2]))
    names(curr.input) <- "inputs"; names(curr.output) <- "vdjca"; names(curr.output2) <- "clna"

    ## Version
    curr.version <- trimws(strsplit(grep("Version", curr.record, value = T)[1], ":")[[1]][2])
    names(curr.version) <- "version"

    ## Total Reads
    curr.total <- trimws(strsplit(grep("Total seq", curr.record, value = T), ':')[[1]][2])
    names(curr.total) <- "total.reads"

    ## Alignment
    curr.Success <- extractRecord("Success", curr.record, c("aligned.reads", "aligned.pct"))
    curr.NoHit <- extractRecord("no hits", curr.record, c("failed.align.no.hits", "pct.no.hits"))
    curr.NoJ <- extractRecord("J hits", curr.record, c("failed.align.no.j", "pct.no.j"))
    curr.Low <- extractRecord("low total", curr.record, c("failed.align.low.score", "pct.low.score"))
    curr.Overlap <- extractRecord("Overlapped:", curr.record, c("num.overlapped", "pct.overlapped"))
    curr.Overlap.Align <- extractRecord("Overlapped and aligned:", curr.record,
                                        c("num.overlapped.and.aligned", "pct.overlapped.and.aligned"))
    curr.Alignment.Aided <- extractRecord("Alignment-aided", curr.record,
                                        c("num.align.aided.overlap", "pct.align.aided.overlap"))
    curr.Overlap.Not.Align <- extractRecord("Overlapped and not", curr.record,
                                            c("num.overlapped.and.not.algned", "pct.overlapped.and.not.aligned"))
    curr.TRB.chains <- extractRecord("TRB chains", curr.record, c("num.TRB.chains", "pct.TRB.chains"))[1]

    ## Assembly
    curr.count <- trimws(strsplit(grep("Final clonotype count", curr.record, value = T), ":")[[1]][2])
    curr.avg.per.clone <- trimws(strsplit(grep("Average number", curr.record, value = T), ":")[[1]][2])
    names(curr.count) <- "clonotype.count"; names(curr.avg.per.clone) <- "avg.reads.per.clonotype"

    curr.reads.used <- extractRecord("clonotypes, percent", curr.record, c("num.reads.used", "pct.used.of.total"))
    curr.reads.cluster <- extractRecord("clonotypes before", curr.record, c("num.reads.used.b4.clust", "pct.of.total"))
    curr.core <- extractRecord("used as a core", curr.record, c("num.reads.used.as.core", "pct.of.used"))
    curr.low <- extractRecord("quality reads", curr.record, c("num.reads.mapped.lowq", "pct.mapped.of.used"))
    curr.clust <- extractRecord("Reads clustered", curr.record, c("num.PCR.error.clust", "pct.PCR.clust.of.used"))
    curr.pre.clust <- extractRecord("pre-clustered", curr.record, c("num.VJC.clust", "pct.VJC.clust.of.used"))
    curr.dropped.lack <- extractRecord("lack of a clone", curr.record, c("num.drop.no.clonal.seq", "pct.dropped.no.clonal"))
    curr.dropped.low <- extractRecord("dropped due to low", curr.record, c("num.drop.lowq", "pct.dropped.lowq"))
    curr.dropped.fail <- extractRecord("failed mapping", curr.record, c("num.drop.fail.map", "pct.dropped.fail.map"))
    curr.dropped.low.clone <- extractRecord("low quality clones", curr.record, c("num.drop.lowq.clone", "pct.dropped.lowq.clone"))
    curr.pcr.correct <-  extractRecord("eliminated by", curr.record, "clonotypes.elim.PCR.error")
    curr.clone.dropped.lowq <- extractRecord("Clonotypes dropped", curr.record, "clonotypes.drop.lowq")
    curr.clone.preclust <- extractRecord("Clonotypes pre-clustered", curr.record, "clonotypes.pre.clust.similar.VJC")
    curr.clone.TRB.chains <- extractRecord("TRB chains", curr.record, c("num.clone.TRB.chains", "pct.clone.TRB.chains"))[2]

  ## Combine into a row to add to data frame
    alignRow_v <- c(curr.date, curr.input, curr.output, curr.output2, curr.version, curr.total,
               curr.Success, curr.NoHit, curr.NoJ, curr.Overlap, curr.Overlap.Align, curr.Overlap.Not.Align)
    alignNames_v <- names(alignRow_v)

    assembleRow_v <- c(curr.date, curr.input, curr.output,, curr.output2, curr.version, curr.count, curr.avg.per.clone,
               curr.reads.used, curr.reads.cluster, curr.core, curr.low, curr.clust, curr.pre.clust,
               curr.dropped.lack, curr.dropped.low, curr.dropped.fail, curr.dropped.low.clone,
               curr.pcr.correct, curr.clone.dropped.lowq, curr.clone.preclust)
    assembleNames_v <- names(assembleRow_v)

  # Populate data frame
  align_df <- rbind(align_df, alignRow_v, stringsAsFactors = F)
  colnames(align_df) <- alignNames_v
  assemble_df <- rbind(assemble_df, assembleRow_v, stringsAsFactors = F)
  colnames(assemble_df) <- assembleNames_v
    
}  #  for

#######################
### Decontamination ###
#######################

if (debug_v) print("Begin Decontam")

### Get files
decontam_qc_files_v <- unlist(strsplit(decontamQCFiles_v, ','))

decontam_output_matrix <- matrix(nrow = length(decontam_qc_files_v), ncol = ncol(read.table(decontam_qc_files_v[1], nrows = 1, header = F, sep = '\t')))

for (i in 1:length(decontam_qc_files_v)){
    ## Read data
    curr_data_df <- read.table(decontam_qc_files_v[i], sep = '\t', header = T, stringsAsFactors = F)
    ## Add to matrix
    decontam_output_matrix[i,] <- unlist(curr_data_df[1,], use.names = F)
} # for

colnames(decontam_output_matrix) <- colnames(curr_data_df)

#####################
### Normalization ###
#####################

if (debug_v) print("Begin Normalization")

# Separate input files
raw.clonotype.count.files <- unlist(strsplit(decontamCloneFiles_v, ','))
normCountFiles_v <- unlist(strsplit(normCountFiles_v, ','))

# Empty data frame
output.data <- NULL

for(i in 1:length(raw.clonotype.count.files))  {
  ## Read in raw and norm
  curr.raw <- read.table(raw.clonotype.count.files[i], sep = '\t', stringsAsFactors = F, header = T)
  curr.normalized <- read.table(raw.clonotype.count.files[i], sep = '\t', stringsAsFactors = F, header = T)

  ## Get column names
  cdr3Col_v <- grep("AA. Seq. CDR3|aaSeqCDR3", colnames(curr.raw), value = T)
  rawCountCol_v <- grep("Clone count|cloneCount", colnames(curr.raw), value = T)
  rawFreqCol_v <- grep("Clone fraction|cloneFraction", colnames(curr.raw), value = T)
  normCountCol_v <- grep("Normalized clone count", colnames(curr.normalized), value = T)
  normFreqCol_v <- grep("Normalized clone fraction", colnames(curr.normalized), value = T)
  nbCountCol_v <- grep("nb.clone.count", colnames(curr.normalized), value = T)
  nbFreqCol_v <- grep("nb.clone.fraction", colnames(curr.normalized), value = T)
  
  ## Check if files are same
  curr.raw.CDR3 <- curr.raw[[cdr3Col_v]]
  curr.normalized.CDR3 <- curr.normalized[[cdr3Col_v]]
  if(!identical(curr.raw.CDR3, curr.normalized.CDR3)) {
    stop("Mistmatch between amino acid CDR3 region, raw and normalized");
  }   #   fi

  ## QC Table
  combined.table <- data.frame(raw.clone.count=curr.raw[[rawCountCol_v]]);
  ncols_v <- 2
  if (length(normCountCol_v) > 0){
    combined.table$median.norm.count <- curr.normalized[[normCountCol_v]]
    ncols_v <- ncols_v + 2
  } # fi
  if (length(nbCountCol_v) > 0){
    combined.table$nb.clone.count <- curr.normalized[[nbCountCol_v]]
    ncols_v <- ncols_v + 2
  }
  combined.table$raw.clone.percent <- curr.raw[[rawFreqCol_v]]
  if (length(normFreqCol_v) > 0){
    combined.table$median.norm.fraction <- curr.normalized[[normFreqCol_v]]
  } # fi
  if (length(nbFreqCol_v) > 0){
    combined.table$nb.clone.fraction <- curr.normalized[[nbFreqCol_v]]
  }
  if (length(normFreqCol_v) > 0){
    combined.table$median.norm.factor <- round((combined.table$median.norm.count / combined.table$raw.clone.count), digits = 1)
  }
  if (length(nbFreqCol_v) > 0){
    combined.table$nb.norm.factor <- round((combined.table$nb.clone.count / combined.table$raw.clone.count), digits = 1)
  }
  
  ## Summarize
  row_v <- apply(combined.table[,1:ncols_v], 2, mean)
  if (length(normFreqCol_v) > 0) {
    summary_v <- as.vector(summary(combined.table$median.norm.factor))[c(1,3,6)]
    names(summary_v) <- c("min.scale.median.norm", "median.scale.median.norm", "max.scale.median.norm")
    row_v <- c(row_v, summary_v)
  }
  if (length(nbFreqCol_v) > 0) {
    summary_v <- as.vector(summary(combined.table$nb.norm.factor))[c(1,3,6)]
    names(summary_v) <- c("min.scale.nb.norm", "median.scale.nb.norm", "max.scale.nb.norm")
    row_v <- c(row_v, summary_v)
  }
  
  ## Combine
  colNames_v <- names(row_v)
  output.data <- rbind(output.data, row_v)
  colnames(output.data) <- colNames_v

  rm(combined.table);
}   #   for i

###############
### Outputs ###
###############

if (debug_v) print("Begin Output")

### Spike Count & Remove Spikes
write.table(summaryOut_df,
            file=spikeCountOut_v,
            quote=FALSE,
            sep="\t",
            row.names=FALSE)

### MiXCR Align
write.table(align_df,
            file = alignOut_v,
            quote = FALSE,
            sep = '\t',
            row.names = FALSE)

### MiXCR Assemble
write.table(assemble_df,
            file = assembleOut_v,
            quote = FALSE,
            sep = '\t',
            row.names = FALSE)

### Decontamination
write.table(decontam_output_matrix,
            file = decontamOut_v,
            sep = '\t',
            quote = FALSE,
            row.names = F)

### Normalization
write.table(output.data,
            file = normOut_v,
            quote = FALSE,
            sep = '\t',
            row.names = FALSE)
